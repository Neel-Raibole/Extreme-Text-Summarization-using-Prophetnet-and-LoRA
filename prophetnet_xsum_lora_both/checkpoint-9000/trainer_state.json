{
  "best_global_step": 9000,
  "best_metric": 4.52786922454834,
  "best_model_checkpoint": "/content/drive/MyDrive/prophetnet_xsum_lora_both/checkpoint-9000",
  "epoch": 2.8230220340312084,
  "eval_steps": 1000,
  "global_step": 9000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01568258448992394,
      "grad_norm": 1.6865004301071167,
      "learning_rate": 3.920000000000001e-06,
      "loss": 7.7631,
      "step": 50
    },
    {
      "epoch": 0.03136516897984788,
      "grad_norm": 1.4910447597503662,
      "learning_rate": 7.92e-06,
      "loss": 7.4503,
      "step": 100
    },
    {
      "epoch": 0.047047753469771816,
      "grad_norm": 0.8198572397232056,
      "learning_rate": 1.1920000000000001e-05,
      "loss": 6.8348,
      "step": 150
    },
    {
      "epoch": 0.06273033795969576,
      "grad_norm": 2.9195291996002197,
      "learning_rate": 1.5920000000000003e-05,
      "loss": 6.2436,
      "step": 200
    },
    {
      "epoch": 0.0784129224496197,
      "grad_norm": 0.49607938528060913,
      "learning_rate": 1.9920000000000002e-05,
      "loss": 5.7807,
      "step": 250
    },
    {
      "epoch": 0.09409550693954363,
      "grad_norm": 0.43433669209480286,
      "learning_rate": 2.392e-05,
      "loss": 5.4541,
      "step": 300
    },
    {
      "epoch": 0.10977809142946758,
      "grad_norm": 0.42482221126556396,
      "learning_rate": 2.792e-05,
      "loss": 5.2389,
      "step": 350
    },
    {
      "epoch": 0.12546067591939153,
      "grad_norm": 0.4443816840648651,
      "learning_rate": 3.1920000000000006e-05,
      "loss": 5.0993,
      "step": 400
    },
    {
      "epoch": 0.14114326040931546,
      "grad_norm": 0.37235283851623535,
      "learning_rate": 3.592e-05,
      "loss": 4.9675,
      "step": 450
    },
    {
      "epoch": 0.1568258448992394,
      "grad_norm": 0.37295523285865784,
      "learning_rate": 3.9920000000000004e-05,
      "loss": 4.8748,
      "step": 500
    },
    {
      "epoch": 0.17250842938916333,
      "grad_norm": 0.39496690034866333,
      "learning_rate": 3.984002611818479e-05,
      "loss": 4.8445,
      "step": 550
    },
    {
      "epoch": 0.18819101387908727,
      "grad_norm": 0.40493568778038025,
      "learning_rate": 3.9676787463271305e-05,
      "loss": 4.8152,
      "step": 600
    },
    {
      "epoch": 0.2038735983690112,
      "grad_norm": 0.37321898341178894,
      "learning_rate": 3.951354880835782e-05,
      "loss": 4.7871,
      "step": 650
    },
    {
      "epoch": 0.21955618285893516,
      "grad_norm": 0.39361485838890076,
      "learning_rate": 3.935031015344434e-05,
      "loss": 4.7744,
      "step": 700
    },
    {
      "epoch": 0.2352387673488591,
      "grad_norm": 0.38467568159103394,
      "learning_rate": 3.9187071498530854e-05,
      "loss": 4.7756,
      "step": 750
    },
    {
      "epoch": 0.25092135183878306,
      "grad_norm": 0.37877514958381653,
      "learning_rate": 3.902383284361737e-05,
      "loss": 4.7494,
      "step": 800
    },
    {
      "epoch": 0.266603936328707,
      "grad_norm": 0.3888612687587738,
      "learning_rate": 3.8860594188703886e-05,
      "loss": 4.7484,
      "step": 850
    },
    {
      "epoch": 0.2822865208186309,
      "grad_norm": 0.413467675447464,
      "learning_rate": 3.869735553379041e-05,
      "loss": 4.7412,
      "step": 900
    },
    {
      "epoch": 0.29796910530855486,
      "grad_norm": 0.39535677433013916,
      "learning_rate": 3.853411687887692e-05,
      "loss": 4.7446,
      "step": 950
    },
    {
      "epoch": 0.3136516897984788,
      "grad_norm": 0.40086203813552856,
      "learning_rate": 3.8370878223963435e-05,
      "loss": 4.7307,
      "step": 1000
    },
    {
      "epoch": 0.3136516897984788,
      "eval_loss": 4.619456768035889,
      "eval_runtime": 280.0632,
      "eval_samples_per_second": 40.462,
      "eval_steps_per_second": 5.06,
      "step": 1000
    },
    {
      "epoch": 0.32933427428840273,
      "grad_norm": 0.44984063506126404,
      "learning_rate": 3.820763956904996e-05,
      "loss": 4.7195,
      "step": 1050
    },
    {
      "epoch": 0.34501685877832666,
      "grad_norm": 0.4283509850502014,
      "learning_rate": 3.8044400914136474e-05,
      "loss": 4.7246,
      "step": 1100
    },
    {
      "epoch": 0.3606994432682506,
      "grad_norm": 0.4321720600128174,
      "learning_rate": 3.7881162259222983e-05,
      "loss": 4.7133,
      "step": 1150
    },
    {
      "epoch": 0.37638202775817453,
      "grad_norm": 0.37116557359695435,
      "learning_rate": 3.7717923604309507e-05,
      "loss": 4.7116,
      "step": 1200
    },
    {
      "epoch": 0.39206461224809847,
      "grad_norm": 0.3831632435321808,
      "learning_rate": 3.755468494939602e-05,
      "loss": 4.7082,
      "step": 1250
    },
    {
      "epoch": 0.4077471967380224,
      "grad_norm": 0.412482351064682,
      "learning_rate": 3.739144629448254e-05,
      "loss": 4.7014,
      "step": 1300
    },
    {
      "epoch": 0.4234297812279464,
      "grad_norm": 0.46077191829681396,
      "learning_rate": 3.722820763956905e-05,
      "loss": 4.6976,
      "step": 1350
    },
    {
      "epoch": 0.4391123657178703,
      "grad_norm": 0.45667925477027893,
      "learning_rate": 3.706496898465557e-05,
      "loss": 4.7143,
      "step": 1400
    },
    {
      "epoch": 0.45479495020779426,
      "grad_norm": 0.410407155752182,
      "learning_rate": 3.690173032974209e-05,
      "loss": 4.6885,
      "step": 1450
    },
    {
      "epoch": 0.4704775346977182,
      "grad_norm": 0.4372352957725525,
      "learning_rate": 3.67384916748286e-05,
      "loss": 4.6962,
      "step": 1500
    },
    {
      "epoch": 0.4861601191876421,
      "grad_norm": 0.4270952641963959,
      "learning_rate": 3.657525301991512e-05,
      "loss": 4.6912,
      "step": 1550
    },
    {
      "epoch": 0.5018427036775661,
      "grad_norm": 0.409076988697052,
      "learning_rate": 3.6412014365001636e-05,
      "loss": 4.6999,
      "step": 1600
    },
    {
      "epoch": 0.51752528816749,
      "grad_norm": 0.40776634216308594,
      "learning_rate": 3.624877571008815e-05,
      "loss": 4.6877,
      "step": 1650
    },
    {
      "epoch": 0.533207872657414,
      "grad_norm": 0.4371771216392517,
      "learning_rate": 3.608553705517467e-05,
      "loss": 4.6946,
      "step": 1700
    },
    {
      "epoch": 0.5488904571473379,
      "grad_norm": 0.4184243381023407,
      "learning_rate": 3.5922298400261185e-05,
      "loss": 4.6958,
      "step": 1750
    },
    {
      "epoch": 0.5645730416372619,
      "grad_norm": NaN,
      "learning_rate": 3.57590597453477e-05,
      "loss": 4.6734,
      "step": 1800
    },
    {
      "epoch": 0.5802556261271857,
      "grad_norm": 0.4471430778503418,
      "learning_rate": 3.559908586353249e-05,
      "loss": 4.683,
      "step": 1850
    },
    {
      "epoch": 0.5959382106171097,
      "grad_norm": 0.4245206117630005,
      "learning_rate": 3.5435847208619e-05,
      "loss": 4.6684,
      "step": 1900
    },
    {
      "epoch": 0.6116207951070336,
      "grad_norm": 0.4732247292995453,
      "learning_rate": 3.527260855370552e-05,
      "loss": 4.688,
      "step": 1950
    },
    {
      "epoch": 0.6273033795969576,
      "grad_norm": 0.46201902627944946,
      "learning_rate": 3.5109369898792035e-05,
      "loss": 4.6783,
      "step": 2000
    },
    {
      "epoch": 0.6273033795969576,
      "eval_loss": 4.58411169052124,
      "eval_runtime": 281.2117,
      "eval_samples_per_second": 40.297,
      "eval_steps_per_second": 5.039,
      "step": 2000
    },
    {
      "epoch": 0.6429859640868815,
      "grad_norm": 0.44097450375556946,
      "learning_rate": 3.494613124387855e-05,
      "loss": 4.6755,
      "step": 2050
    },
    {
      "epoch": 0.6586685485768055,
      "grad_norm": 0.4601118862628937,
      "learning_rate": 3.478289258896507e-05,
      "loss": 4.6631,
      "step": 2100
    },
    {
      "epoch": 0.6743511330667294,
      "grad_norm": 0.47547563910484314,
      "learning_rate": 3.4619653934051584e-05,
      "loss": 4.6761,
      "step": 2150
    },
    {
      "epoch": 0.6900337175566533,
      "grad_norm": 0.5417371392250061,
      "learning_rate": 3.445641527913811e-05,
      "loss": 4.6556,
      "step": 2200
    },
    {
      "epoch": 0.7057163020465773,
      "grad_norm": 0.3929346799850464,
      "learning_rate": 3.429317662422462e-05,
      "loss": 4.6806,
      "step": 2250
    },
    {
      "epoch": 0.7213988865365012,
      "grad_norm": 0.4486924409866333,
      "learning_rate": 3.412993796931113e-05,
      "loss": 4.6741,
      "step": 2300
    },
    {
      "epoch": 0.7370814710264252,
      "grad_norm": 0.40252506732940674,
      "learning_rate": 3.3966699314397656e-05,
      "loss": 4.6749,
      "step": 2350
    },
    {
      "epoch": 0.7527640555163491,
      "grad_norm": 0.41984206438064575,
      "learning_rate": 3.380346065948417e-05,
      "loss": 4.6745,
      "step": 2400
    },
    {
      "epoch": 0.768446640006273,
      "grad_norm": 0.4312341809272766,
      "learning_rate": 3.364022200457068e-05,
      "loss": 4.6795,
      "step": 2450
    },
    {
      "epoch": 0.7841292244961969,
      "grad_norm": 0.541949450969696,
      "learning_rate": 3.3476983349657205e-05,
      "loss": 4.6627,
      "step": 2500
    },
    {
      "epoch": 0.7998118089861209,
      "grad_norm": 0.4901038110256195,
      "learning_rate": 3.331374469474372e-05,
      "loss": 4.6613,
      "step": 2550
    },
    {
      "epoch": 0.8154943934760448,
      "grad_norm": 0.39730584621429443,
      "learning_rate": 3.315050603983023e-05,
      "loss": 4.6676,
      "step": 2600
    },
    {
      "epoch": 0.8311769779659688,
      "grad_norm": 0.4739513099193573,
      "learning_rate": 3.2987267384916753e-05,
      "loss": 4.6727,
      "step": 2650
    },
    {
      "epoch": 0.8468595624558928,
      "grad_norm": 0.41419291496276855,
      "learning_rate": 3.282402873000327e-05,
      "loss": 4.6546,
      "step": 2700
    },
    {
      "epoch": 0.8625421469458167,
      "grad_norm": 0.5405188798904419,
      "learning_rate": 3.2660790075089786e-05,
      "loss": 4.6606,
      "step": 2750
    },
    {
      "epoch": 0.8782247314357406,
      "grad_norm": 0.43723833560943604,
      "learning_rate": 3.2497551420176295e-05,
      "loss": 4.6682,
      "step": 2800
    },
    {
      "epoch": 0.8939073159256645,
      "grad_norm": 0.4670291841030121,
      "learning_rate": 3.233431276526282e-05,
      "loss": 4.6407,
      "step": 2850
    },
    {
      "epoch": 0.9095899004155885,
      "grad_norm": 0.4277383089065552,
      "learning_rate": 3.2171074110349335e-05,
      "loss": 4.6547,
      "step": 2900
    },
    {
      "epoch": 0.9252724849055124,
      "grad_norm": 0.3964120149612427,
      "learning_rate": 3.200783545543585e-05,
      "loss": 4.6592,
      "step": 2950
    },
    {
      "epoch": 0.9409550693954364,
      "grad_norm": 0.4495511054992676,
      "learning_rate": 3.1847861573620636e-05,
      "loss": 4.6624,
      "step": 3000
    },
    {
      "epoch": 0.9409550693954364,
      "eval_loss": 4.56531286239624,
      "eval_runtime": 280.7887,
      "eval_samples_per_second": 40.358,
      "eval_steps_per_second": 5.046,
      "step": 3000
    },
    {
      "epoch": 0.9566376538853603,
      "grad_norm": 0.45939186215400696,
      "learning_rate": 3.168462291870715e-05,
      "loss": 4.6582,
      "step": 3050
    },
    {
      "epoch": 0.9723202383752843,
      "grad_norm": 0.4540294110774994,
      "learning_rate": 3.152138426379367e-05,
      "loss": 4.6541,
      "step": 3100
    },
    {
      "epoch": 0.9880028228652082,
      "grad_norm": 0.5018311738967896,
      "learning_rate": 3.1358145608880185e-05,
      "loss": 4.6549,
      "step": 3150
    },
    {
      "epoch": 1.0034501685877832,
      "grad_norm": 0.44694748520851135,
      "learning_rate": 3.11949069539667e-05,
      "loss": 4.5892,
      "step": 3200
    },
    {
      "epoch": 1.0191327530777072,
      "grad_norm": 0.42476558685302734,
      "learning_rate": 3.103166829905322e-05,
      "loss": 4.6388,
      "step": 3250
    },
    {
      "epoch": 1.0348153375676312,
      "grad_norm": 0.42964866757392883,
      "learning_rate": 3.0868429644139734e-05,
      "loss": 4.6401,
      "step": 3300
    },
    {
      "epoch": 1.050497922057555,
      "grad_norm": 0.456417441368103,
      "learning_rate": 3.070519098922625e-05,
      "loss": 4.6406,
      "step": 3350
    },
    {
      "epoch": 1.066180506547479,
      "grad_norm": 0.46308210492134094,
      "learning_rate": 3.0541952334312766e-05,
      "loss": 4.6378,
      "step": 3400
    },
    {
      "epoch": 1.081863091037403,
      "grad_norm": 0.45262259244918823,
      "learning_rate": 3.0378713679399286e-05,
      "loss": 4.6399,
      "step": 3450
    },
    {
      "epoch": 1.097545675527327,
      "grad_norm": 0.4552595317363739,
      "learning_rate": 3.02154750244858e-05,
      "loss": 4.6422,
      "step": 3500
    },
    {
      "epoch": 1.1132282600172507,
      "grad_norm": 0.48030683398246765,
      "learning_rate": 3.0052236369572315e-05,
      "loss": 4.645,
      "step": 3550
    },
    {
      "epoch": 1.1289108445071747,
      "grad_norm": 0.46284711360931396,
      "learning_rate": 2.9888997714658835e-05,
      "loss": 4.6457,
      "step": 3600
    },
    {
      "epoch": 1.1445934289970987,
      "grad_norm": 0.4170723557472229,
      "learning_rate": 2.972575905974535e-05,
      "loss": 4.6465,
      "step": 3650
    },
    {
      "epoch": 1.1602760134870227,
      "grad_norm": 0.5963824987411499,
      "learning_rate": 2.9562520404831864e-05,
      "loss": 4.6485,
      "step": 3700
    },
    {
      "epoch": 1.1759585979769467,
      "grad_norm": 0.4431411921977997,
      "learning_rate": 2.9399281749918383e-05,
      "loss": 4.6329,
      "step": 3750
    },
    {
      "epoch": 1.1916411824668705,
      "grad_norm": 0.4493848383426666,
      "learning_rate": 2.92360430950049e-05,
      "loss": 4.6512,
      "step": 3800
    },
    {
      "epoch": 1.2073237669567944,
      "grad_norm": 0.45940250158309937,
      "learning_rate": 2.907280444009142e-05,
      "loss": 4.6422,
      "step": 3850
    },
    {
      "epoch": 1.2230063514467184,
      "grad_norm": 0.48067909479141235,
      "learning_rate": 2.8909565785177932e-05,
      "loss": 4.6369,
      "step": 3900
    },
    {
      "epoch": 1.2386889359366424,
      "grad_norm": 0.44667643308639526,
      "learning_rate": 2.8746327130264448e-05,
      "loss": 4.6245,
      "step": 3950
    },
    {
      "epoch": 1.2543715204265662,
      "grad_norm": 0.4467020332813263,
      "learning_rate": 2.8583088475350968e-05,
      "loss": 4.6309,
      "step": 4000
    },
    {
      "epoch": 1.2543715204265662,
      "eval_loss": 4.552643299102783,
      "eval_runtime": 283.0946,
      "eval_samples_per_second": 40.029,
      "eval_steps_per_second": 5.005,
      "step": 4000
    },
    {
      "epoch": 1.2700541049164902,
      "grad_norm": 0.5344533920288086,
      "learning_rate": 2.8419849820437484e-05,
      "loss": 4.6499,
      "step": 4050
    },
    {
      "epoch": 1.2857366894064142,
      "grad_norm": 0.4526316523551941,
      "learning_rate": 2.8256611165523997e-05,
      "loss": 4.6447,
      "step": 4100
    },
    {
      "epoch": 1.3014192738963382,
      "grad_norm": 0.45568737387657166,
      "learning_rate": 2.8093372510610513e-05,
      "loss": 4.6219,
      "step": 4150
    },
    {
      "epoch": 1.3171018583862621,
      "grad_norm": 0.46090826392173767,
      "learning_rate": 2.7930133855697033e-05,
      "loss": 4.6324,
      "step": 4200
    },
    {
      "epoch": 1.332784442876186,
      "grad_norm": 0.4390932023525238,
      "learning_rate": 2.7766895200783546e-05,
      "loss": 4.6298,
      "step": 4250
    },
    {
      "epoch": 1.34846702736611,
      "grad_norm": 0.4560924768447876,
      "learning_rate": 2.7603656545870062e-05,
      "loss": 4.6251,
      "step": 4300
    },
    {
      "epoch": 1.364149611856034,
      "grad_norm": 0.5250700116157532,
      "learning_rate": 2.744041789095658e-05,
      "loss": 4.6461,
      "step": 4350
    },
    {
      "epoch": 1.3798321963459579,
      "grad_norm": 0.5553830862045288,
      "learning_rate": 2.7277179236043098e-05,
      "loss": 4.649,
      "step": 4400
    },
    {
      "epoch": 1.3955147808358817,
      "grad_norm": 0.4876505136489868,
      "learning_rate": 2.711394058112961e-05,
      "loss": 4.6337,
      "step": 4450
    },
    {
      "epoch": 1.4111973653258056,
      "grad_norm": 0.4714139997959137,
      "learning_rate": 2.695070192621613e-05,
      "loss": 4.639,
      "step": 4500
    },
    {
      "epoch": 1.4268799498157296,
      "grad_norm": 0.519134521484375,
      "learning_rate": 2.6787463271302647e-05,
      "loss": 4.6306,
      "step": 4550
    },
    {
      "epoch": 1.4425625343056536,
      "grad_norm": 0.4531741440296173,
      "learning_rate": 2.6624224616389166e-05,
      "loss": 4.6237,
      "step": 4600
    },
    {
      "epoch": 1.4582451187955776,
      "grad_norm": 0.48524123430252075,
      "learning_rate": 2.646098596147568e-05,
      "loss": 4.6344,
      "step": 4650
    },
    {
      "epoch": 1.4739277032855014,
      "grad_norm": 0.5414241552352905,
      "learning_rate": 2.6297747306562195e-05,
      "loss": 4.6204,
      "step": 4700
    },
    {
      "epoch": 1.4896102877754254,
      "grad_norm": 0.4825681746006012,
      "learning_rate": 2.6134508651648715e-05,
      "loss": 4.6134,
      "step": 4750
    },
    {
      "epoch": 1.5052928722653494,
      "grad_norm": 0.44609326124191284,
      "learning_rate": 2.597126999673523e-05,
      "loss": 4.6179,
      "step": 4800
    },
    {
      "epoch": 1.5209754567552731,
      "grad_norm": 0.4424218535423279,
      "learning_rate": 2.5808031341821744e-05,
      "loss": 4.6456,
      "step": 4850
    },
    {
      "epoch": 1.5366580412451971,
      "grad_norm": 0.4824249744415283,
      "learning_rate": 2.564479268690826e-05,
      "loss": 4.6336,
      "step": 4900
    },
    {
      "epoch": 1.552340625735121,
      "grad_norm": 0.4892885386943817,
      "learning_rate": 2.548155403199478e-05,
      "loss": 4.6284,
      "step": 4950
    },
    {
      "epoch": 1.568023210225045,
      "grad_norm": 0.45509517192840576,
      "learning_rate": 2.5318315377081293e-05,
      "loss": 4.618,
      "step": 5000
    },
    {
      "epoch": 1.568023210225045,
      "eval_loss": 4.542126178741455,
      "eval_runtime": 280.3629,
      "eval_samples_per_second": 40.419,
      "eval_steps_per_second": 5.054,
      "step": 5000
    },
    {
      "epoch": 1.5840194464047674,
      "grad_norm": 0.49190038442611694,
      "learning_rate": 1.9933804060017654e-05,
      "loss": 4.6358,
      "step": 5050
    },
    {
      "epoch": 1.5997020308946914,
      "grad_norm": 0.5213016271591187,
      "learning_rate": 1.9713150926743162e-05,
      "loss": 4.626,
      "step": 5100
    },
    {
      "epoch": 1.6153846153846154,
      "grad_norm": 0.5392733216285706,
      "learning_rate": 1.949249779346867e-05,
      "loss": 4.6202,
      "step": 5150
    },
    {
      "epoch": 1.6310671998745394,
      "grad_norm": 0.47056612372398376,
      "learning_rate": 1.9271844660194177e-05,
      "loss": 4.638,
      "step": 5200
    },
    {
      "epoch": 1.6467497843644634,
      "grad_norm": 0.4618031978607178,
      "learning_rate": 1.9051191526919684e-05,
      "loss": 4.6305,
      "step": 5250
    },
    {
      "epoch": 1.6624323688543872,
      "grad_norm": 0.4779626131057739,
      "learning_rate": 1.883053839364519e-05,
      "loss": 4.6228,
      "step": 5300
    },
    {
      "epoch": 1.6781149533443112,
      "grad_norm": 0.4978514611721039,
      "learning_rate": 1.86098852603707e-05,
      "loss": 4.6205,
      "step": 5350
    },
    {
      "epoch": 1.693797537834235,
      "grad_norm": 0.543796718120575,
      "learning_rate": 1.8389232127096207e-05,
      "loss": 4.6246,
      "step": 5400
    },
    {
      "epoch": 1.709480122324159,
      "grad_norm": 0.5315858721733093,
      "learning_rate": 1.816857899382171e-05,
      "loss": 4.6137,
      "step": 5450
    },
    {
      "epoch": 1.725162706814083,
      "grad_norm": 0.4954666495323181,
      "learning_rate": 1.7947925860547222e-05,
      "loss": 4.6192,
      "step": 5500
    },
    {
      "epoch": 1.740845291304007,
      "grad_norm": 0.451352059841156,
      "learning_rate": 1.772727272727273e-05,
      "loss": 4.6212,
      "step": 5550
    },
    {
      "epoch": 1.7565278757939309,
      "grad_norm": 0.6390230059623718,
      "learning_rate": 1.7506619593998234e-05,
      "loss": 4.623,
      "step": 5600
    },
    {
      "epoch": 1.7722104602838549,
      "grad_norm": 0.43818771839141846,
      "learning_rate": 1.7285966460723745e-05,
      "loss": 4.6202,
      "step": 5650
    },
    {
      "epoch": 1.7878930447737789,
      "grad_norm": 0.46677166223526,
      "learning_rate": 1.7065313327449252e-05,
      "loss": 4.6242,
      "step": 5700
    },
    {
      "epoch": 1.8035756292637026,
      "grad_norm": 0.4730200469493866,
      "learning_rate": 1.6844660194174757e-05,
      "loss": 4.6182,
      "step": 5750
    },
    {
      "epoch": 1.8192582137536266,
      "grad_norm": 0.4788529574871063,
      "learning_rate": 1.6624007060900267e-05,
      "loss": 4.6324,
      "step": 5800
    },
    {
      "epoch": 1.8349407982435504,
      "grad_norm": 0.4747196435928345,
      "learning_rate": 1.6403353927625775e-05,
      "loss": 4.6181,
      "step": 5850
    },
    {
      "epoch": 1.8506233827334744,
      "grad_norm": 0.4811553657054901,
      "learning_rate": 1.618270079435128e-05,
      "loss": 4.6107,
      "step": 5900
    },
    {
      "epoch": 1.8663059672233984,
      "grad_norm": 0.5213520526885986,
      "learning_rate": 1.596204766107679e-05,
      "loss": 4.6093,
      "step": 5950
    },
    {
      "epoch": 1.8819885517133224,
      "grad_norm": 0.4911254942417145,
      "learning_rate": 1.5741394527802298e-05,
      "loss": 4.6232,
      "step": 6000
    },
    {
      "epoch": 1.8819885517133224,
      "eval_loss": 4.533448219299316,
      "eval_runtime": 276.0524,
      "eval_samples_per_second": 41.05,
      "eval_steps_per_second": 5.133,
      "step": 6000
    },
    {
      "epoch": 1.8976711362032463,
      "grad_norm": 0.5003141164779663,
      "learning_rate": 1.5520741394527802e-05,
      "loss": 4.6131,
      "step": 6050
    },
    {
      "epoch": 1.9133537206931703,
      "grad_norm": 0.4726751744747162,
      "learning_rate": 1.5300088261253313e-05,
      "loss": 4.6115,
      "step": 6100
    },
    {
      "epoch": 1.9290363051830943,
      "grad_norm": 0.7089945673942566,
      "learning_rate": 1.5079435127978819e-05,
      "loss": 4.6069,
      "step": 6150
    },
    {
      "epoch": 1.944718889673018,
      "grad_norm": 0.535487174987793,
      "learning_rate": 1.4858781994704326e-05,
      "loss": 4.6084,
      "step": 6200
    },
    {
      "epoch": 1.960401474162942,
      "grad_norm": 0.500314474105835,
      "learning_rate": 1.4638128861429834e-05,
      "loss": 4.6103,
      "step": 6250
    },
    {
      "epoch": 1.9760840586528658,
      "grad_norm": 0.457366406917572,
      "learning_rate": 1.4417475728155341e-05,
      "loss": 4.6156,
      "step": 6300
    },
    {
      "epoch": 1.9917666431427898,
      "grad_norm": 0.4663641154766083,
      "learning_rate": 1.4196822594880849e-05,
      "loss": 4.6063,
      "step": 6350
    },
    {
      "epoch": 2.0075276405551636,
      "grad_norm": 0.44055208563804626,
      "learning_rate": 1.3976169461606356e-05,
      "loss": 4.6362,
      "step": 6400
    },
    {
      "epoch": 2.0232102250450876,
      "grad_norm": 0.82745361328125,
      "learning_rate": 1.3755516328331864e-05,
      "loss": 4.6148,
      "step": 6450
    },
    {
      "epoch": 2.038892809535011,
      "grad_norm": 0.4462004601955414,
      "learning_rate": 1.353486319505737e-05,
      "loss": 4.617,
      "step": 6500
    },
    {
      "epoch": 2.054575394024935,
      "grad_norm": 0.532008171081543,
      "learning_rate": 1.3314210061782877e-05,
      "loss": 4.6055,
      "step": 6550
    },
    {
      "epoch": 2.070257978514859,
      "grad_norm": 0.5228047370910645,
      "learning_rate": 1.3093556928508387e-05,
      "loss": 4.6141,
      "step": 6600
    },
    {
      "epoch": 2.085940563004783,
      "grad_norm": 0.4664050042629242,
      "learning_rate": 1.2872903795233892e-05,
      "loss": 4.616,
      "step": 6650
    },
    {
      "epoch": 2.101623147494707,
      "grad_norm": 0.5638903379440308,
      "learning_rate": 1.26522506619594e-05,
      "loss": 4.601,
      "step": 6700
    },
    {
      "epoch": 2.117305731984631,
      "grad_norm": 0.48779526352882385,
      "learning_rate": 1.243159752868491e-05,
      "loss": 4.6134,
      "step": 6750
    },
    {
      "epoch": 2.132988316474555,
      "grad_norm": 0.4958973228931427,
      "learning_rate": 1.2210944395410415e-05,
      "loss": 4.6062,
      "step": 6800
    },
    {
      "epoch": 2.148670900964479,
      "grad_norm": 0.4773027002811432,
      "learning_rate": 1.1990291262135923e-05,
      "loss": 4.6158,
      "step": 6850
    },
    {
      "epoch": 2.164353485454403,
      "grad_norm": 0.7055538296699524,
      "learning_rate": 1.1769638128861432e-05,
      "loss": 4.6105,
      "step": 6900
    },
    {
      "epoch": 2.1800360699443266,
      "grad_norm": 0.4860297441482544,
      "learning_rate": 1.1548984995586938e-05,
      "loss": 4.602,
      "step": 6950
    },
    {
      "epoch": 2.1957186544342506,
      "grad_norm": 0.44498828053474426,
      "learning_rate": 1.1328331862312445e-05,
      "loss": 4.6085,
      "step": 7000
    },
    {
      "epoch": 2.1957186544342506,
      "eval_loss": 4.531530380249023,
      "eval_runtime": 275.8735,
      "eval_samples_per_second": 41.077,
      "eval_steps_per_second": 5.136,
      "step": 7000
    },
    {
      "epoch": 2.2114012389241746,
      "grad_norm": 0.4666939675807953,
      "learning_rate": 1.1107678729037954e-05,
      "loss": 4.6035,
      "step": 7050
    },
    {
      "epoch": 2.2270838234140986,
      "grad_norm": 0.44159379601478577,
      "learning_rate": 1.088702559576346e-05,
      "loss": 4.5909,
      "step": 7100
    },
    {
      "epoch": 2.2427664079040226,
      "grad_norm": 0.49258413910865784,
      "learning_rate": 1.0666372462488968e-05,
      "loss": 4.6039,
      "step": 7150
    },
    {
      "epoch": 2.2584489923939466,
      "grad_norm": 0.5296972393989563,
      "learning_rate": 1.0445719329214477e-05,
      "loss": 4.6011,
      "step": 7200
    },
    {
      "epoch": 2.2741315768838706,
      "grad_norm": 0.5628964304924011,
      "learning_rate": 1.0225066195939983e-05,
      "loss": 4.6079,
      "step": 7250
    },
    {
      "epoch": 2.2898141613737946,
      "grad_norm": 0.5017942190170288,
      "learning_rate": 1.000441306266549e-05,
      "loss": 4.6011,
      "step": 7300
    },
    {
      "epoch": 2.305496745863718,
      "grad_norm": 0.5029870867729187,
      "learning_rate": 9.783759929390998e-06,
      "loss": 4.605,
      "step": 7350
    },
    {
      "epoch": 2.321179330353642,
      "grad_norm": 0.475271075963974,
      "learning_rate": 9.563106796116506e-06,
      "loss": 4.5958,
      "step": 7400
    },
    {
      "epoch": 2.336861914843566,
      "grad_norm": 0.5062645077705383,
      "learning_rate": 9.342453662842013e-06,
      "loss": 4.5977,
      "step": 7450
    },
    {
      "epoch": 2.35254449933349,
      "grad_norm": 0.5423598289489746,
      "learning_rate": 9.12180052956752e-06,
      "loss": 4.6091,
      "step": 7500
    },
    {
      "epoch": 2.368227083823414,
      "grad_norm": 0.5058696269989014,
      "learning_rate": 8.901147396293028e-06,
      "loss": 4.5983,
      "step": 7550
    },
    {
      "epoch": 2.383909668313338,
      "grad_norm": 0.5905162692070007,
      "learning_rate": 8.680494263018536e-06,
      "loss": 4.609,
      "step": 7600
    },
    {
      "epoch": 2.399592252803262,
      "grad_norm": 0.5048708915710449,
      "learning_rate": 8.459841129744043e-06,
      "loss": 4.5972,
      "step": 7650
    },
    {
      "epoch": 2.415274837293186,
      "grad_norm": 0.4889639616012573,
      "learning_rate": 8.239187996469551e-06,
      "loss": 4.5995,
      "step": 7700
    },
    {
      "epoch": 2.43095742178311,
      "grad_norm": 0.48384103178977966,
      "learning_rate": 8.018534863195058e-06,
      "loss": 4.6059,
      "step": 7750
    },
    {
      "epoch": 2.446640006273034,
      "grad_norm": 0.4753381013870239,
      "learning_rate": 7.797881729920566e-06,
      "loss": 4.6074,
      "step": 7800
    },
    {
      "epoch": 2.4623225907629576,
      "grad_norm": 0.4356797933578491,
      "learning_rate": 7.5772285966460736e-06,
      "loss": 4.6097,
      "step": 7850
    },
    {
      "epoch": 2.4780051752528816,
      "grad_norm": 0.5090115070343018,
      "learning_rate": 7.35657546337158e-06,
      "loss": 4.5925,
      "step": 7900
    },
    {
      "epoch": 2.4936877597428055,
      "grad_norm": 0.5119380354881287,
      "learning_rate": 7.135922330097088e-06,
      "loss": 4.6039,
      "step": 7950
    },
    {
      "epoch": 2.5093703442327295,
      "grad_norm": 0.5259440541267395,
      "learning_rate": 6.9152691968225945e-06,
      "loss": 4.6163,
      "step": 8000
    },
    {
      "epoch": 2.5093703442327295,
      "eval_loss": 4.52891206741333,
      "eval_runtime": 276.5761,
      "eval_samples_per_second": 40.972,
      "eval_steps_per_second": 5.123,
      "step": 8000
    },
    {
      "epoch": 2.5250529287226535,
      "grad_norm": 0.6203532814979553,
      "learning_rate": 6.694616063548103e-06,
      "loss": 4.6017,
      "step": 8050
    },
    {
      "epoch": 2.5407355132125775,
      "grad_norm": 0.5165071487426758,
      "learning_rate": 6.4739629302736105e-06,
      "loss": 4.6064,
      "step": 8100
    },
    {
      "epoch": 2.5564180977025015,
      "grad_norm": 0.6190013289451599,
      "learning_rate": 6.253309796999117e-06,
      "loss": 4.611,
      "step": 8150
    },
    {
      "epoch": 2.572100682192425,
      "grad_norm": 0.497395396232605,
      "learning_rate": 6.0326566637246256e-06,
      "loss": 4.6242,
      "step": 8200
    },
    {
      "epoch": 2.587783266682349,
      "grad_norm": 0.4669298231601715,
      "learning_rate": 5.812003530450133e-06,
      "loss": 4.5997,
      "step": 8250
    },
    {
      "epoch": 2.603465851172273,
      "grad_norm": 0.4901062250137329,
      "learning_rate": 5.59135039717564e-06,
      "loss": 4.6033,
      "step": 8300
    },
    {
      "epoch": 2.619148435662197,
      "grad_norm": 0.5653919577598572,
      "learning_rate": 5.370697263901148e-06,
      "loss": 4.6094,
      "step": 8350
    },
    {
      "epoch": 2.634831020152121,
      "grad_norm": 0.4954538643360138,
      "learning_rate": 5.150044130626656e-06,
      "loss": 4.5914,
      "step": 8400
    },
    {
      "epoch": 2.650513604642045,
      "grad_norm": 0.46343401074409485,
      "learning_rate": 4.9293909973521625e-06,
      "loss": 4.6068,
      "step": 8450
    },
    {
      "epoch": 2.666196189131969,
      "grad_norm": 0.5270052552223206,
      "learning_rate": 4.70873786407767e-06,
      "loss": 4.593,
      "step": 8500
    },
    {
      "epoch": 2.681878773621893,
      "grad_norm": 0.5105222463607788,
      "learning_rate": 4.4880847308031775e-06,
      "loss": 4.6101,
      "step": 8550
    },
    {
      "epoch": 2.697561358111817,
      "grad_norm": 0.5362582802772522,
      "learning_rate": 4.267431597528685e-06,
      "loss": 4.6194,
      "step": 8600
    },
    {
      "epoch": 2.713243942601741,
      "grad_norm": 0.46682974696159363,
      "learning_rate": 4.046778464254193e-06,
      "loss": 4.6031,
      "step": 8650
    },
    {
      "epoch": 2.728926527091665,
      "grad_norm": 0.46828728914260864,
      "learning_rate": 3.8261253309797e-06,
      "loss": 4.6068,
      "step": 8700
    },
    {
      "epoch": 2.7446091115815885,
      "grad_norm": 0.452789306640625,
      "learning_rate": 3.6054721977052077e-06,
      "loss": 4.5989,
      "step": 8750
    },
    {
      "epoch": 2.7602916960715125,
      "grad_norm": 0.4489538371562958,
      "learning_rate": 3.384819064430715e-06,
      "loss": 4.6148,
      "step": 8800
    },
    {
      "epoch": 2.7759742805614365,
      "grad_norm": 0.5178669095039368,
      "learning_rate": 3.164165931156223e-06,
      "loss": 4.6,
      "step": 8850
    },
    {
      "epoch": 2.7916568650513605,
      "grad_norm": 0.515501081943512,
      "learning_rate": 2.94351279788173e-06,
      "loss": 4.6127,
      "step": 8900
    },
    {
      "epoch": 2.8073394495412844,
      "grad_norm": 0.5182440876960754,
      "learning_rate": 2.7228596646072375e-06,
      "loss": 4.6019,
      "step": 8950
    },
    {
      "epoch": 2.8230220340312084,
      "grad_norm": 0.4886564314365387,
      "learning_rate": 2.506619593998235e-06,
      "loss": 4.6026,
      "step": 9000
    },
    {
      "epoch": 2.8230220340312084,
      "eval_loss": 4.52786922454834,
      "eval_runtime": 277.4092,
      "eval_samples_per_second": 40.849,
      "eval_steps_per_second": 5.108,
      "step": 9000
    }
  ],
  "logging_steps": 50,
  "max_steps": 9564,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.505338957201408e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
